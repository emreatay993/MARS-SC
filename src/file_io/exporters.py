"""
Export helpers for MARS-SC (Solution Combination).

Functions for exporting analysis results to CSV/APDL and related formats.
"""

import json
import pandas as pd
import numpy as np
from typing import Optional, List, Dict

from core.data_models import MaterialProfileData


def export_to_csv(data: pd.DataFrame, filename: str) -> None:
    """
    Export a DataFrame to CSV format.
    
    Args:
        data: DataFrame to export.
        filename: Path to the output CSV file.
    """
    data.to_csv(filename, index=False)


def generate_apdl_ic(node_ids: np.ndarray, vel_x: np.ndarray, 
                    vel_y: np.ndarray, vel_z: np.ndarray) -> str:
    """
    Generate APDL initial condition commands from velocity data.
    
    This function wraps the legacy fea_utilities function but can be extended
    with additional functionality.
    
    Args:
        node_ids: Array of node numbers.
        vel_x: Array of velocities in the X direction.
        vel_y: Array of velocities in the Y direction.
        vel_z: Array of velocities in the Z direction.
    
    Returns:
        String containing the APDL IC commands, ready to be saved.
    """
    apdl_commands = [
        "! APDL Initial Condition (Velocity) Commands",
        "! Generated by MARS-SC: Solution Combination",
        "! Velocity Units: [mm/s]",
        "FINISH",
        "/SOLU",
        "! Applying Initial Conditions for Velocity"
    ]
    
    # Iterate through each node and create the IC command for each velocity component
    for i, node in enumerate(node_ids):
        # Ensure values are flattened if they are in a column vector
        vx = vel_x.flatten()[i]
        vy = vel_y.flatten()[i]
        vz = vel_z.flatten()[i]
        apdl_commands.append(f"IC,{int(node)},VELX,{vx:.6E}")
        apdl_commands.append(f"IC,{int(node)},VELY,{vy:.6E}")
        apdl_commands.append(f"IC,{int(node)},VELZ,{vz:.6E}")
    
    apdl_commands.append("! End of Initial Conditions")
    
    # Join all commands into a single string with newlines
    return "\n".join(apdl_commands)


def export_apdl_ic(node_ids: np.ndarray, vel_x: np.ndarray, 
                   vel_y: np.ndarray, vel_z: np.ndarray, 
                   filename: str) -> None:
    """
    Export APDL initial condition commands to a file.
    
    Args:
        node_ids: Array of node numbers.
        vel_x: Array of velocities in the X direction.
        vel_y: Array of velocities in the Y direction.
        vel_z: Array of velocities in the Z direction.
        filename: Path to the output file.
    """
    apdl_commands = generate_apdl_ic(node_ids, vel_x, vel_y, vel_z)
    with open(filename, 'w') as f:
        f.write(apdl_commands)


def export_time_point_results(node_ids: np.ndarray, 
                              node_coords: np.ndarray,
                              scalar_data: np.ndarray,
                              scalar_name: str,
                              filename: str) -> None:
    """
    Export time point results to CSV format.
    
    Args:
        node_ids: Array of node IDs.
        node_coords: Array of node coordinates (n_nodes, 3).
        scalar_data: Scalar data at each node.
        scalar_name: Name of the scalar field.
        filename: Path to the output CSV file.
    """
    df_out = pd.DataFrame()
    
    if node_ids is not None:
        df_out['NodeID'] = node_ids
    
    if node_coords is not None:
        df_out['X'] = node_coords[:, 0]
        df_out['Y'] = node_coords[:, 1]
        df_out['Z'] = node_coords[:, 2]
    
    df_out[scalar_name] = scalar_data
    
    df_out.to_csv(filename, index=False)


def export_mesh_to_csv(mesh, scalar_name: str, filename: str) -> None:
    """
    Export PyVista mesh with scalar data to CSV.
    
    Args:
        mesh: PyVista mesh object with scalar data.
        scalar_name: Name of the active scalar field.
        filename: Path to the output CSV file.
    """
    coords = mesh.points
    scalar_data = mesh[scalar_name]
    
    df_out = pd.DataFrame()
    
    if 'NodeID' in mesh.array_names:
        df_out['NodeID'] = mesh['NodeID']
    
    df_out['X'] = coords[:, 0]
    df_out['Y'] = coords[:, 1]
    df_out['Z'] = coords[:, 2]
    df_out[scalar_name] = scalar_data
    
    df_out.to_csv(filename, index=False)


def export_results_with_headers(filename: str, node_ids: np.ndarray, 
                                node_coords: Optional[np.ndarray],
                                data: np.ndarray, header: str) -> None:
    """
    Export results to CSV with custom header.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        data: Data array to export.
        header: Header name for the data column.
    """
    df_out = pd.DataFrame({'NodeID': node_ids, header: data})
    
    if node_coords is not None:
        df_coords = pd.DataFrame(node_coords, columns=['X', 'Y', 'Z'])
        df_out = pd.concat([df_out, df_coords], axis=1)
    
    df_out.to_csv(filename, index=False)


def export_material_profile(profile: MaterialProfileData, filename: str) -> None:
    """
    Export a material profile to JSON format.

    Args:
        profile: MaterialProfileData instance containing all material tables.
        filename: Destination path for the JSON file.
    """
    payload = {
        "youngs_modulus": {
            "columns": list(profile.youngs_modulus.columns),
            "data": profile.youngs_modulus.values.tolist(),
        },
        "poisson_ratio": {
            "columns": list(profile.poisson_ratio.columns),
            "data": profile.poisson_ratio.values.tolist(),
        },
        "plastic_curves": [],
    }

    for temperature in sorted(profile.plastic_curves.keys()):
        curve_df = profile.plastic_curves[temperature]
        payload["plastic_curves"].append({
            "temperature": float(temperature),
            "columns": list(curve_df.columns),
            "data": curve_df.values.tolist(),
        })

    with open(filename, "w", encoding="utf-8-sig") as fh:
        json.dump(payload, fh, ensure_ascii=False, indent=2)


# =============================================================================
# MARS-SC (Solution Combination) Export Functions
# =============================================================================

def export_envelope_results(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    max_values: Optional[np.ndarray] = None,
    min_values: Optional[np.ndarray] = None,
    combo_of_max: Optional[np.ndarray] = None,
    combo_of_min: Optional[np.ndarray] = None,
    result_type: str = "von_mises",
    combination_names: Optional[List[str]] = None
) -> None:
    """
    Export envelope results (max/min over combinations) to CSV format.
    
    The envelope represents the maximum and/or minimum stress values across
    all combinations for each node, along with which combination produced
    that extreme value.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        max_values: Array of maximum stress values over all combinations.
        min_values: Array of minimum stress values over all combinations.
        combo_of_max: Array of combination indices where max occurred.
        combo_of_min: Array of combination indices where min occurred.
        result_type: Type of stress result (e.g., "von_mises", "max_principal").
        combination_names: Optional list of combination names for labeling.
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(len(max_values or min_values))
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Format result type for column headers
    result_label = result_type.replace('_', ' ').title()
    
    # Add max envelope columns
    if max_values is not None:
        df[f'Max {result_label} [MPa]'] = max_values
        if combo_of_max is not None:
            # Display 1-based combination number for user-friendliness
            df['Combination of Max (#)'] = (combo_of_max.astype(int) + 1)
            if combination_names is not None:
                df['Combination of Max (Name)'] = [
                    combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
                    for idx in combo_of_max
                ]
    
    # Add min envelope columns
    if min_values is not None:
        df[f'Min {result_label} [MPa]'] = min_values
        if combo_of_min is not None:
            # Display 1-based combination number for user-friendliness
            df['Combination of Min (#)'] = (combo_of_min.astype(int) + 1)
            if combination_names is not None:
                df['Combination of Min (Name)'] = [
                    combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
                    for idx in combo_of_min
                ]
    
    df.to_csv(filename, index=False)


def export_single_combination(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    stress_values: np.ndarray,
    combination_index: int,
    combination_name: str = "",
    result_type: str = "von_mises",
    include_tensor: bool = False,
    stress_tensor: Optional[np.ndarray] = None
) -> None:
    """
    Export single combination stress results to CSV format.
    
    This exports the stress values for all nodes computed at a specific
    combination (using the combination table coefficients).
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        stress_values: Array of scalar stress values (e.g., von Mises).
        combination_index: Index of the combination being exported.
        combination_name: Name of the combination for metadata.
        result_type: Type of stress result (e.g., "von_mises", "max_principal").
        include_tensor: If True and stress_tensor provided, include full tensor.
        stress_tensor: Optional full stress tensor array (n_nodes, 6) in Voigt order.
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(len(stress_values))
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Format result type for column header
    result_label = result_type.replace('_', ' ').title()
    df[f'{result_label} [MPa]'] = stress_values
    
    # Add full tensor if requested and available
    if include_tensor and stress_tensor is not None:
        voigt_labels = ['Sxx', 'Syy', 'Szz', 'Sxy', 'Syz', 'Sxz']
        for i, label in enumerate(voigt_labels):
            df[f'{label} [MPa]'] = stress_tensor[:, i]
    
    # Add metadata as comment in first row (write separately)
    # Instead, we'll add combination info as columns
    df['Combination Index'] = combination_index
    df['Combination Name'] = combination_name
    
    df.to_csv(filename, index=False)


def export_combination_history(
    filename: str,
    node_id: int,
    combination_indices: np.ndarray,
    stress_values: np.ndarray,
    combination_names: Optional[List[str]] = None,
    result_type: str = "von_mises",
    corrected_values: Optional[np.ndarray] = None,
    plastic_strain: Optional[np.ndarray] = None
) -> None:
    """
    Export combination history for a single node to CSV format.
    
    This exports the stress values across all combinations for a specific
    node, useful for identifying which combinations cause critical stresses.
    
    Args:
        filename: Path to the output CSV file.
        node_id: ID of the node being exported.
        combination_indices: Array of combination indices.
        stress_values: Array of stress values at each combination.
        combination_names: Optional list of combination names.
        result_type: Type of stress result.
        corrected_values: Optional array of plasticity-corrected values.
        plastic_strain: Optional array of plastic strain values.
    """
    df = pd.DataFrame()
    
    # Display 1-based combination number for user-friendliness
    df['Combination #'] = (np.asarray(combination_indices).astype(int) + 1)
    
    if combination_names is not None:
        df['Combination Name'] = [
            combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
            for idx in combination_indices
        ]
    
    result_label = result_type.replace('_', ' ').title()
    df[f'{result_label} [MPa]'] = stress_values
    
    if corrected_values is not None:
        df[f'{result_label} Corrected [MPa]'] = corrected_values
    
    if plastic_strain is not None:
        df['Plastic Strain'] = plastic_strain
    
    # Add node ID as metadata column
    df['Node ID'] = node_id
    
    df.to_csv(filename, index=False)


def export_all_combinations_batch(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    all_combinations_data: np.ndarray,
    combination_names: Optional[List[str]] = None,
    result_type: str = "von_mises"
) -> None:
    """
    Export all combination results for all nodes to a single CSV.
    
    Creates a wide-format CSV where each column represents a different
    combination and each row represents a node.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        all_combinations_data: Array of shape (n_combinations, n_nodes).
        combination_names: Optional list of combination names.
        result_type: Type of stress result.
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(all_combinations_data.shape[1])
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Add each combination as a column
    result_label = result_type.replace('_', ' ').title()
    num_combinations = all_combinations_data.shape[0]
    
    for i in range(num_combinations):
        if combination_names is not None and i < len(combination_names):
            col_name = f'{combination_names[i]} [{result_label}]'
        else:
            col_name = f'Combo_{i} [{result_label}]'
        df[col_name] = all_combinations_data[i, :]
    
    df.to_csv(filename, index=False)


# =============================================================================
# Nodal Forces Export Functions
# =============================================================================

def export_nodal_forces_envelope(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    max_magnitude: Optional[np.ndarray] = None,
    min_magnitude: Optional[np.ndarray] = None,
    combo_of_max: Optional[np.ndarray] = None,
    combo_of_min: Optional[np.ndarray] = None,
    combination_names: Optional[List[str]] = None,
    force_unit: str = "N"
) -> None:
    """
    Export nodal forces envelope results (max/min magnitude over combinations) to CSV.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        max_magnitude: Array of maximum force magnitudes over all combinations.
        min_magnitude: Array of minimum force magnitudes over all combinations.
        combo_of_max: Array of combination indices where max occurred.
        combo_of_min: Array of combination indices where min occurred.
        combination_names: Optional list of combination names for labeling.
        force_unit: Force unit string (e.g., "N").
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(len(max_magnitude or min_magnitude))
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Add max envelope columns
    if max_magnitude is not None:
        df[f'Max Force Magnitude [{force_unit}]'] = max_magnitude
        if combo_of_max is not None:
            df['Combination of Max (#)'] = (combo_of_max.astype(int) + 1)
            if combination_names is not None:
                df['Combination of Max (Name)'] = [
                    combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
                    for idx in combo_of_max
                ]
    
    # Add min envelope columns
    if min_magnitude is not None:
        df[f'Min Force Magnitude [{force_unit}]'] = min_magnitude
        if combo_of_min is not None:
            df['Combination of Min (#)'] = (combo_of_min.astype(int) + 1)
            if combination_names is not None:
                df['Combination of Min (Name)'] = [
                    combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
                    for idx in combo_of_min
                ]
    
    df.to_csv(filename, index=False)


def export_nodal_forces_single_combination(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    fx: np.ndarray,
    fy: np.ndarray,
    fz: np.ndarray,
    combination_index: int,
    combination_name: str = "",
    force_unit: str = "N"
) -> None:
    """
    Export nodal forces for a single combination to CSV format.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        fx, fy, fz: Force component arrays.
        combination_index: Index of the combination being exported.
        combination_name: Name of the combination for metadata.
        force_unit: Force unit string.
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(len(fx))
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Add force components
    df[f'FX [{force_unit}]'] = fx
    df[f'FY [{force_unit}]'] = fy
    df[f'FZ [{force_unit}]'] = fz
    
    # Add force magnitude
    magnitude = np.sqrt(fx**2 + fy**2 + fz**2)
    df[f'Force Magnitude [{force_unit}]'] = magnitude
    
    # Add combination info
    df['Combination Index'] = combination_index
    df['Combination Name'] = combination_name
    
    df.to_csv(filename, index=False)


def export_nodal_forces_all_combinations(
    filename: str,
    node_ids: np.ndarray,
    node_coords: Optional[np.ndarray],
    all_combo_fx: np.ndarray,
    all_combo_fy: np.ndarray,
    all_combo_fz: np.ndarray,
    combination_names: Optional[List[str]] = None,
    force_unit: str = "N"
) -> None:
    """
    Export all nodal force combinations for all nodes to a single CSV.
    
    Creates a wide-format CSV where each combination has FX, FY, FZ, Magnitude columns.
    
    Args:
        filename: Path to the output CSV file.
        node_ids: Array of node IDs.
        node_coords: Optional array of node coordinates (n_nodes, 3).
        all_combo_fx: FX array of shape (n_combinations, n_nodes).
        all_combo_fy: FY array of shape (n_combinations, n_nodes).
        all_combo_fz: FZ array of shape (n_combinations, n_nodes).
        combination_names: Optional list of combination names.
        force_unit: Force unit string.
    """
    df = pd.DataFrame()
    
    # Add node IDs
    df['NodeID'] = node_ids.flatten() if node_ids is not None else range(all_combo_fx.shape[1])
    
    # Add coordinates if provided
    if node_coords is not None:
        df['X'] = node_coords[:, 0]
        df['Y'] = node_coords[:, 1]
        df['Z'] = node_coords[:, 2]
    
    # Add each combination as columns
    num_combinations = all_combo_fx.shape[0]
    
    for i in range(num_combinations):
        combo_name = combination_names[i] if combination_names and i < len(combination_names) else f"Combo_{i}"
        
        df[f'{combo_name}_FX [{force_unit}]'] = all_combo_fx[i, :]
        df[f'{combo_name}_FY [{force_unit}]'] = all_combo_fy[i, :]
        df[f'{combo_name}_FZ [{force_unit}]'] = all_combo_fz[i, :]
        
        # Calculate and add magnitude
        magnitude = np.sqrt(all_combo_fx[i, :]**2 + all_combo_fy[i, :]**2 + all_combo_fz[i, :]**2)
        df[f'{combo_name}_Magnitude [{force_unit}]'] = magnitude
    
    df.to_csv(filename, index=False)


def export_nodal_forces_history(
    filename: str,
    node_id: int,
    combination_indices: np.ndarray,
    fx: np.ndarray,
    fy: np.ndarray,
    fz: np.ndarray,
    combination_names: Optional[List[str]] = None,
    force_unit: str = "N"
) -> None:
    """
    Export nodal forces history for a single node to CSV format.
    
    Args:
        filename: Path to the output CSV file.
        node_id: ID of the node being exported.
        combination_indices: Array of combination indices.
        fx, fy, fz: Force component arrays at each combination.
        combination_names: Optional list of combination names.
        force_unit: Force unit string.
    """
    df = pd.DataFrame()
    
    # Display 1-based combination number
    df['Combination #'] = (np.asarray(combination_indices).astype(int) + 1)
    
    if combination_names is not None:
        df['Combination Name'] = [
            combination_names[int(idx)] if 0 <= int(idx) < len(combination_names) else f"Combo {int(idx) + 1}"
            for idx in combination_indices
        ]
    
    df[f'FX [{force_unit}]'] = fx
    df[f'FY [{force_unit}]'] = fy
    df[f'FZ [{force_unit}]'] = fz
    
    # Add magnitude
    magnitude = np.sqrt(fx**2 + fy**2 + fz**2)
    df[f'Force Magnitude [{force_unit}]'] = magnitude
    
    # Add node ID as metadata column
    df['Node ID'] = node_id
    
    df.to_csv(filename, index=False)
